import time, json, statistics, redis
from kafka import KafkaConsumer
from pymongo import MongoClient
from utils.logger import Logger


# TODO åˆå§‹åŒ– logger
logger = Logger(console_name=f'.consumer_console',
                file_name=f'.consumer_file')


# TODO åˆå§‹åŒ– Kafka Consumer
KAFKA_BROKER = 'localhost:9092'
TOPIC = 'test-data'
consumer = KafkaConsumer(
    TOPIC,
    bootstrap_servers=[KAFKA_BROKER],
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    group_id='python-consumer',
    value_deserializer=lambda v: json.loads(v.decode('utf-8'))
)


# TODO åˆå§‹åŒ– Redis
REDIS_HOST = '127.0.0.1'
REDIS_PORT = 6379
REDIS_PASSWORD = 'redis_pass'

redis_client = None

try:
    redis_client = redis.Redis(
        host=REDIS_HOST,
        port=REDIS_PORT,
        password=REDIS_PASSWORD,
        db=0
    )
    redis_client.ping()
    logger.warning('Redis æ¸¬è©¦é€£æ¥æˆåŠŸä¸¦é€šéé©—è­‰ï¼')

except redis.exceptions.AuthenticationError as e:
    logger.error('é©—è­‰å¤±æ•—ï¼šè«‹æª¢æŸ¥å¯†ç¢¼æ˜¯å¦æ­£ç¢º')

except Exception as e:
    logger.error('Redis é€£æ¥æˆ–æ“ä½œå¤±æ•—')


# TODO åˆå§‹åŒ– MongoDB
MONGO_USERNAME = 'mongo_user'
MONGO_PASSWORD = 'mongo_pass'
MONGO_HOST = 'localhost:27017'
MONGO_URI = f"mongodb://{MONGO_USERNAME}:{MONGO_PASSWORD}@{MONGO_HOST}/"

mongo_client = MongoClient(MONGO_URI)
db = mongo_client['perf_test'] # æ‡‰ç”¨ç¨‹å¼è³‡æ–™åº«

try:
    db.command('ping')
    logger.warning("MongoDB é€£æ¥ä¸¦é©—è­‰æˆåŠŸï¼")

except Exception as e:
    logger.error('MongoDB é€£æ¥æˆ–é©—è­‰å¤±æ•—')

collection = db['records']


# TODO æ¶ˆè²» Kafka è¨Šæ¯ä¸¦å¯«å…¥ Redis å’Œ MongoDB
latencies = []
count = 0
start_time = time.time()

logger.warning('ğŸ”¥ Consumer started... waiting for messages')
for message in consumer:
    # è§£æ Kafka è¨Šæ¯
    data = message.value

    # è¨ˆç®—å»¶é²
    recv_time = time.time()
    latency = recv_time - data['timestamp']
    latencies.append(latency)

    # å¯«å…¥ Redis (ä»¥ device_id ç‚º key)
    redis_client.set(data['device_id'], json.dumps(data))

    # å¯«å…¥ MongoDB
    collection.insert_one({
        'device_id': data['device_id'],
        'value': data['value'],
        'producer_ts': data['timestamp'],
        'consumer_ts': recv_time,
        'latency': latency
    })

    count += 1
    if count % 1000 == 0:
        elapsed = time.time() - start_time
        throughput = count / elapsed
        avg_latency = statistics.mean(latencies)
        logger.info(f'Processed: {count} msgs | '
              f'Throughput: {throughput:.2f} msg/s | '
              f'Avg Latency: {avg_latency*1000:.2f} ms')